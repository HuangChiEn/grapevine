# Note : this in easy_configer format, plz reference doc.
# src: https://easy-configer.readthedocs.io/en/latest/index.html

## Global paramters 

# ? reproducability setup
seed = 42
deterministic = True

# Execution stage : str in options [train, finetune, test]
exe_stage = 'train'


#----------------------------------------------------------------
## Common setup (model, datasets, trainer)
[model_params]  
    your_setup = None

[dataset_params]
    your_setup = None

# src: https://lightning.ai/docs/pytorch/stable/common/trainer.html#init
[trainer]
    # debug for tra/val loop via fast run!
    fast_dev_run = False
    # reproduce algo
    deterministic = ${cfg.deterministic}
    # profile
    profiler = None
    # gpu & precision setup
    accelerator = 'gpu'
    devices = [1]
    precision = '16'
    # train related
    accumulate_grad_batches = 1
    max_epochs = 45
    # default_root_dir (os.mkdir auto) can not change default folder name
    default_root_dir = "test/"
    log_every_n_steps = 100 

# src: https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.WandbLogger.html#wandblogger
[logger]
    log_it = True
    [logger.setup]
        project = 'project_name'
        offline = True

#----------------------------------------------------------------
## Parameters setup for init fit method or model wrt. different exe_stage
[train_params]
    your_setup = None
    # automatically restores model, epoch, step, LR schedulers, etc...
    # don't forgot to enlarge max_epoch
    resume_path = None

#----------------------------------------------------------------
[finetune_params]
    PATH = '/some_path/checkpoints/epoch=xx-step=xxxx.ckpt'
    your_setup = None

#----------------------------------------------------------------
[test_params]
    PATH = {$cfg.finetune_params.PATH}@str